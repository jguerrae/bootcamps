{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRERIAS\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import nltk\r\n",
    "from nltk.stem.porter import *\r\n",
    "import re\r\n",
    "from unidecode import unidecode\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer \r\n",
    "from sklearn.decomposition import LatentDirichletAllocation \r\n",
    "from scipy.sparse import csr_matrix \r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import pyLDAvis\r\n",
    "from pyLDAvis import sklearn as sklearnlda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMPIEZA INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"2_final_db.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           Comédienne\n",
      "1                                   Empresa dedicada a\n",
      "2    Actrice, chanteuse-auteure, Clown/Neztoile Ros...\n",
      "3                                           Comédienne\n",
      "4                          Senior Javascript Developer\n",
      "5                                            Regisseur\n",
      "6                                    Backend developer\n",
      "7                                            Directora\n",
      "8                                 Full Stack Developer\n",
      "9                                 Senior IOS Developer\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"job_title\"][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning: invalid escape sequence \\.\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\.\n",
      "<ipython-input-30-fe7f9bf425bd>:4: DeprecationWarning: invalid escape sequence \\.\n",
      "  df[\"job_title\"]=df[\"job_title\"].str.replace('[>/,\\.!?\\-!?\\n\\)\\(\\r]', ' ') #eliminar caracteres raros\n"
     ]
    }
   ],
   "source": [
    "#LIMPIEZA\r\n",
    "df[\"job_title\"]=df[\"job_title\"].astype(str)\r\n",
    "df[\"job_title\"] = df[\"job_title\"].str.lower() # minuscula\r\n",
    "df[\"job_title\"]=df[\"job_title\"].str.replace('[>/,\\.!?\\-!?\\n\\)\\(\\r]', ' ') #eliminar caracteres raros\r\n",
    "df[\"job_title\"]=df[\"job_title\"].str.replace(' +', ' ')\r\n",
    "df[\"job_title\"] = df[\"job_title\"].map(lambda x: unidecode(x)) #homgeneizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           comedienne\n",
      "1                                   empresa dedicada a\n",
      "2    actrice chanteuse auteure clown neztoile rosa ...\n",
      "3                                           comedienne\n",
      "4                          senior javascript developer\n",
      "5                                            regisseur\n",
      "6                                    backend developer\n",
      "7                                            directora\n",
      "8                                 full stack developer\n",
      "9                                 senior ios developer\n",
      "Name: job_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"job_title\"][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN PARA LEMATIZAR\r\n",
    "# stemmer = PorterStemmer()\r\n",
    "\r\n",
    "from nltk.stem.snowball import SnowballStemmer\r\n",
    "stemmer = SnowballStemmer(language=\"english\")\r\n",
    "\r\n",
    "def lem(texto):\r\n",
    "    l = texto.split(\" \")\r\n",
    "    for e in range(len(l)):\r\n",
    "        l[e] = stemmer.stem(l[e])\r\n",
    "    text = \" \".join(l)\r\n",
    "    return text\r\n",
    "\r\n",
    "df[\"job_title_l\"] = df[\"job_title\"].map(lambda x: lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                            comedienn\n",
      "1                                   empresa dedicada a\n",
      "2    actric chanteus auteur clown neztoil rosa tapi...\n",
      "3                                            comedienn\n",
      "4                            senior javascript develop\n",
      "5                                            regisseur\n",
      "6                                      backend develop\n",
      "7                                            directora\n",
      "8                                   full stack develop\n",
      "9                                    senior io develop\n",
      "Name: job_title_l, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#¿COMO SE VE CON LA LEMATIZACIÓN?\r\n",
    "print(df[\"job_title_l\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora construiremos la matriz término-documento\r\n",
    "n_vocab=600\r\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8, min_df=2, max_features=n_vocab, stop_words='english', ngram_range=(1,3)) \r\n",
    "tf = tf_vectorizer.fit_transform(df[\"job_title\"]) \r\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF_detallada=pd.DataFrame(csr_matrix(tf).todense(), columns=tf_feature_names)\r\n",
    "# TF_detallada.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frecuencias=pd.DataFrame(TF_detallada.sum(), index=tf_feature_names, columns=['Freq'])\r\n",
    "# frecuencias.sort_values(by=['Freq'], ascending=False, inplace=True)\r\n",
    "# frecuencias.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n"
     ]
    }
   ],
   "source": [
    "#MODELO PARA TITLES SIN STEM\r\n",
    "\r\n",
    "for i in range(3,11):\r\n",
    "    lda = LatentDirichletAllocation(n_components=i, max_iter=11,doc_topic_prior=0.1, topic_word_prior=0.1, n_jobs=-1,random_state=353, verbose=1) #CONSTRUYO EL MODELO\r\n",
    "    lda.fit(tf) # Esti\r\n",
    "    LDAvis_prepared=sklearnlda.prepare(lda, tf, tf_vectorizer ) # Preparo el modelo y sus resultados para la visualización\r\n",
    "    pyLDAvis.save_html(LDAvis_prepared, f'LDA_{i}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora construiremos la matriz término-documento\r\n",
    "n_vocab=600\r\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8, min_df=2, max_features=n_vocab, stop_words='english', ngram_range=(1,3)) \r\n",
    "tf = tf_vectorizer.fit_transform(df[\"job_title_l\"]) \r\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n"
     ]
    }
   ],
   "source": [
    "#MODELO PARA TITLES CON STEM\r\n",
    "\r\n",
    "for i in range(3,11):\r\n",
    "    lda = LatentDirichletAllocation(n_components=i, max_iter=11,doc_topic_prior=0.1, topic_word_prior=0.1, n_jobs=-1,random_state=353, verbose=1) #CONSTRUYO EL MODELO\r\n",
    "    lda.fit(tf) # Esti\r\n",
    "    LDAvis_prepared=sklearnlda.prepare(lda, tf, tf_vectorizer ) # Preparo el modelo y sus resultados para la visualización\r\n",
    "    pyLDAvis.save_html(LDAvis_prepared, f'L_LDA_{i}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python385jvsc74a57bd006cb5fed7a19db1a3b234843391dc1a69eede94e92f070202b04797e91c1cb37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}